# instalar la utilidad wget para poder descargar de Internet contenido
sudo yum install wget
                 
# con wget descargamos contenido de la bibliotea Gutenberg - Twain and Cooper
wget https://datos.comunidad.madrid/catalogo/dataset/cb5b856f-71a4-4e34-8539-84a7e994c972/resource/9fd86617-370a-4770-8a92-0c42ea02d6a1/download/calidad_aire_datos_dia.csv

                 
# Movemos el fichero
# DS para Deerslayer
# HF para  Huckleberry Finn
mv calidad_aire_datos_dia.csv DS.txt

                 
# Creamos nuestro directorio HdFS
hadoop fs -mkdir -p  /user/DataLake
                 
# AÃ±adimos el fichero al Data Lake
hadoop fs -put DS.txt /user/DataLake/
# Comprobamos si el fichero se encuentra en el directorio
hadoop fs -ls /user/DataLake/                 
                 

hadoop fs -put DS.txt /user/DataLake/

# Se puede trabajar con ficheros comprimidos
gzip DS.txt 
hadoop fs -put DS.txt.gz /user/DataLake/
                 


